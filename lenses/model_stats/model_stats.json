{"EleutherAI/gpt-neo-125M": {"num_layers": 11, "context_size": 768}, "EleutherAI/gpt-neo-1.3B": {"num_layers": 23, "context_size": 2048}, "EleutherAI/gpt-neo-2.7B": {"num_layers": 31, "context_size": 2560}, "EleutherAI/pythia-12b-deduped": {"num_layers": 35, "context_size": 5120}, "facebook/opt-125m": {"num_layers": 11, "context_size": 768}, "facebook/opt-1.3b": {"num_layers": 23, "context_size": 2048}, "bigscience/bloom-560m": {"num_layers": 23, "context_size": 1024}}